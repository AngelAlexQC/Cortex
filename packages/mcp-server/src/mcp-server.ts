import {
  ContextGuard,
  ContextRouter,
  createEmbeddingProvider,
  type Memory,
  MemoryStore,
  ProjectScanner,
} from '@ecuabyte/cortex-core';
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import { CallToolRequestSchema, ListToolsRequestSchema } from '@modelcontextprotocol/sdk/types.js';

const store = new MemoryStore();
const router = new ContextRouter(store);
const guard = new ContextGuard();

// CLI Argument Handling for `generate-config`
import { parseArgs } from 'node:util';

try {
  const args = process.argv.slice(2);
  if (args[0] === 'generate-config') {
    const { values } = parseArgs({
      args: args,
      options: {
        target: {
          type: 'string',
        },
      },
      strict: false, // allow params we don't know yet (though we should know them)
    });

    const target = values.target as string | undefined;
    const targets = ['claude', 'claude-desktop', 'cursor', 'windsurf', 'vscode', 'zed', 'goose'];

    if (!target || !targets.includes(target)) {
      console.error(`Usage: cortex-mcp generate-config --target <${targets.join('|')}>`);
      process.exit(1);
    }

    const command = 'npx';
    const cmdArgs = ['-y', '@ecuabyte/cortex-mcp-server'];
    let config: Record<string, unknown> = {};

    switch (target) {
      case 'claude':
      case 'claude-desktop':
      case 'cursor':
      case 'windsurf':
      case 'vscode':
        config = {
          mcpServers: {
            cortex: {
              command,
              args: cmdArgs,
            },
          },
        };
        break;
      case 'zed':
        config = {
          context_servers: {
            'cortex-memory': {
              command: {
                path: command,
                args: cmdArgs,
              },
              settings: {},
            },
          },
        };
        break;
      case 'goose':
        console.log(`Run this command to configure Goose:`);
        console.log(`goose configure mcp add cortex "${command} ${cmdArgs.join(' ')}"`);
        process.exit(0);
    }

    console.log(JSON.stringify(config, null, 2));
    process.exit(0);
  }
} catch (e) {
  // If parsing fails or other issues, just ignore and proceed to server start
  // or print error if it was clearly a CLI attempt
  if (process.argv[2] === 'generate-config') {
    console.error('Error generating config:', e);
    process.exit(1);
  }
}

// Initialize embedding provider if available (Ollama or OpenAI)
let embeddingInitialized = false;
(async () => {
  try {
    const provider = await createEmbeddingProvider({
      openaiApiKey: process.env['OPENAI_API_KEY'],
    });
    if (provider) {
      store.setEmbeddingProvider(provider);
      router.setEmbeddingProvider(provider);
      embeddingInitialized = true;
      console.error(`[Cortex] Embedding provider initialized: ${provider.model}`);
    }
  } catch (e) {
    console.error('[Cortex] Failed to initialize embedding provider:', e);
  }
})();

const server = new Server(
  {
    name: 'cortex-memory',
    version: '0.3.0',
  },
  {
    capabilities: {
      tools: {},
    },
  }
);

// List available tools
server.setRequestHandler(ListToolsRequestSchema, async () => {
  return {
    tools: [
      {
        name: 'cortex_search',
        description: 'Search through project memories (facts, decisions, code patterns, configs)',
        inputSchema: {
          type: 'object',
          properties: {
            query: {
              type: 'string',
              description: 'Search query to find relevant memories',
            },
            type: {
              type: 'string',
              enum: ['fact', 'decision', 'code', 'config', 'note'],
              description: 'Filter by memory type (optional)',
            },
            limit: {
              type: 'number',
              description: 'Maximum number of results to return (default: 10)',
              default: 10,
            },
            semantic: {
              type: 'boolean',
              description:
                'Use semantic (AI) search instead of keyword search. Requires Ollama or OpenAI.',
              default: false,
            },
          },
          required: ['query'],
        },
      },
      {
        name: 'cortex_add',
        description: 'Add a new memory to the knowledge base',
        inputSchema: {
          type: 'object',
          properties: {
            content: {
              type: 'string',
              description: 'The content/description of the memory',
            },
            type: {
              type: 'string',
              enum: ['fact', 'decision', 'code', 'config', 'note'],
              description: 'Type of memory',
            },
            source: {
              type: 'string',
              description: 'Source of the memory (e.g., file path, URL, conversation)',
            },
            tags: {
              type: 'array',
              items: { type: 'string' },
              description: 'Optional tags for categorization',
            },
          },
          required: ['content', 'type', 'source'],
        },
      },
      {
        name: 'cortex_list',
        description: 'List recent memories, optionally filtered by type',
        inputSchema: {
          type: 'object',
          properties: {
            type: {
              type: 'string',
              enum: ['fact', 'decision', 'code', 'config', 'note'],
              description: 'Filter by memory type (optional)',
            },
            limit: {
              type: 'number',
              description: 'Maximum number of results (default: 20)',
              default: 20,
            },
          },
        },
      },
      {
        name: 'cortex_stats',
        description: 'Get statistics about stored memories',
        inputSchema: {
          type: 'object',
          properties: {},
        },
      },
      {
        name: 'cortex_context',
        description:
          'Get intelligent, task-relevant context. Uses AI-powered routing to find the most useful memories for your current task.',
        inputSchema: {
          type: 'object',
          properties: {
            task: {
              type: 'string',
              description: 'Description of what you are currently working on',
            },
            currentFile: {
              type: 'string',
              description: 'Current file path for additional context relevance (optional)',
            },
            tags: {
              type: 'array',
              items: { type: 'string' },
              description: 'Filter by specific tags (optional)',
            },
            type: {
              type: 'string',
              enum: ['fact', 'decision', 'code', 'config', 'note'],
              description: 'Filter by memory type (optional)',
            },
            limit: {
              type: 'number',
              description: 'Maximum number of context items (default: 5)',
              default: 5,
            },
          },
          required: ['task'],
        },
      },
      {
        name: 'cortex_guard',
        description:
          'Check content for sensitive data (API keys, secrets, PII) before sharing. Returns filtered content or warnings.',
        inputSchema: {
          type: 'object',
          properties: {
            content: {
              type: 'string',
              description: 'Content to check/filter for sensitive data',
            },
            filters: {
              type: 'array',
              items: {
                type: 'string',
                enum: [
                  'api_keys',
                  'secrets',
                  'emails',
                  'urls_auth',
                  'credit_cards',
                  'phone_numbers',
                  'ip_addresses',
                  'pii',
                ],
              },
              description: 'Types of sensitive data to filter (default: all)',
            },
            mode: {
              type: 'string',
              enum: ['redact', 'block', 'warn'],
              description:
                'How to handle sensitive data: redact (replace with [REDACTED]), block (return empty if found), warn (flag but keep)',
              default: 'redact',
            },
          },
          required: ['content'],
        },
      },
      {
        name: 'cortex_scan',
        description:
          'Scan a project directory to extract and store context automatically. Finds TODOs, README info, configs, architecture decisions. Returns extracted data for AI analysis.',
        inputSchema: {
          type: 'object',
          properties: {
            path: {
              type: 'string',
              description: 'Project directory path to scan (defaults to current working directory)',
            },
            save: {
              type: 'boolean',
              description: 'Whether to save extracted memories to Cortex (default: true)',
              default: true,
            },
          },
        },
      },
      {
        name: 'cortex_auto_save',
        description:
          'ALWAYS call this at the end of conversations where important decisions, patterns, or facts were discussed. Automatically analyzes and saves relevant memories. Use this to build persistent context across sessions.',
        inputSchema: {
          type: 'object',
          properties: {
            conversation_summary: {
              type: 'string',
              description: 'Brief summary of what was discussed in this conversation',
            },
            memories: {
              type: 'array',
              items: {
                type: 'object',
                properties: {
                  content: {
                    type: 'string',
                    description: 'The memory content to save',
                  },
                  type: {
                    type: 'string',
                    enum: ['fact', 'decision', 'code', 'config', 'note'],
                    description: 'Type of memory',
                  },
                  tags: {
                    type: 'array',
                    items: { type: 'string' },
                    description: 'Tags for categorization',
                  },
                },
                required: ['content', 'type'],
              },
              description:
                'Array of memories to save from this conversation. Include all important decisions, patterns, and facts discussed.',
            },
          },
          required: ['conversation_summary', 'memories'],
        },
      },
      {
        name: 'cortex_remember',
        description:
          'Quick way to save a single important piece of information. Use when the user says something like "remember this" or when you encounter an important decision.',
        inputSchema: {
          type: 'object',
          properties: {
            content: {
              type: 'string',
              description: 'What to remember',
            },
            type: {
              type: 'string',
              enum: ['fact', 'decision', 'code', 'config', 'note'],
              description: 'Type of memory (default: note)',
              default: 'note',
            },
            tags: {
              type: 'array',
              items: { type: 'string' },
              description: 'Optional tags',
            },
          },
          required: ['content'],
        },
      },
      {
        name: 'cortex_recall',
        description:
          'Quickly recall relevant context for the current task. Call this at the START of conversations to load context from previous sessions.',
        inputSchema: {
          type: 'object',
          properties: {
            query: {
              type: 'string',
              description: 'What to recall - describe your current task or topic',
            },
            limit: {
              type: 'number',
              description: 'Maximum memories to recall (default: 5)',
              default: 5,
            },
          },
          required: ['query'],
        },
      },
    ],
  };
});

// Handle tool calls
server.setRequestHandler(CallToolRequestSchema, async (request) => {
  const { name, arguments: args } = request.params;

  try {
    switch (name) {
      case 'cortex_search': {
        if (!args) throw new Error('Missing arguments');
        const query = args['query'] as string;
        const type = args['type'] as string | undefined;
        const limit = (args['limit'] as number) || 10;
        const semantic = (args['semantic'] as boolean) || false;

        let results: Memory[];
        let searchMode = 'keyword';

        if (semantic && embeddingInitialized) {
          // Use semantic search
          const semanticResults = await store.searchSemantic(query, {
            type: type as Memory['type'],
            limit,
            minScore: 0.3,
          });
          results = semanticResults.map((r) => r.memory);
          searchMode = 'semantic';
        } else {
          // Use keyword search
          results = await store.search(query, { type, limit });
        }

        return {
          content: [
            {
              type: 'text',
              text:
                results.length > 0
                  ? `Found ${results.length} memories (${searchMode} search):\n\n` +
                    results
                      .map(
                        (m: Memory, i: number) =>
                          `${i + 1}. [${m.type}] ${m.content}\n   Source: ${m.source}\n   Created: ${m.createdAt}`
                      )
                      .join('\n\n')
                  : `No memories found matching your query (${searchMode} search).`,
            },
          ],
        };
      }

      case 'cortex_add': {
        if (!args) throw new Error('Missing arguments');
        const content = args['content'] as string;
        const type = args['type'] as Memory['type'];
        const source = args['source'] as string;
        const tags = args['tags'] as string[] | undefined;

        const id = await store.add({ content, type, source, tags });

        return {
          content: [
            {
              type: 'text',
              text: `âœ“ Memory added successfully (ID: ${id})`,
            },
          ],
        };
      }

      case 'cortex_list': {
        const type = args?.['type'] as string | undefined;
        const limit = (args?.['limit'] as number) || 20;

        const memories = await store.list({ type, limit });

        return {
          content: [
            {
              type: 'text',
              text:
                memories.length > 0
                  ? `${memories.length} memories:\n\n` +
                    memories
                      .map(
                        (m: Memory, i: number) =>
                          `${i + 1}. [${m.type}] ${m.content}\n   Source: ${m.source}`
                      )
                      .join('\n\n')
                  : 'No memories stored yet.',
            },
          ],
        };
      }

      case 'cortex_stats': {
        const stats = await store.stats();
        const typeBreakdown = Object.entries(stats.byType)
          .map(([type, count]) => `  ${type}: ${count}`)
          .join('\n');

        return {
          content: [
            {
              type: 'text',
              text: `ðŸ“Š Cortex Memory Statistics\n\nTotal memories: ${stats.total}\n\nBy type:\n${
                typeBreakdown || '  (none yet)'
              }`,
            },
          ],
        };
      }

      case 'cortex_context': {
        if (!args) throw new Error('Missing arguments');
        const task = args['task'] as string;
        const currentFile = args['currentFile'] as string | undefined;
        const tags = args['tags'] as string[] | undefined;
        const type = args['type'] as Memory['type'] | undefined;
        const limit = (args['limit'] as number) || 5;

        const results = await router.routeWithScores({ task, currentFile, tags, type, limit });

        if (results.length === 0) {
          return {
            content: [
              {
                type: 'text',
                text: 'No relevant context found for your task. Try adding some memories first with cortex_add.',
              },
            ],
          };
        }

        const contextText = results
          .map(
            (r, i) =>
              `${i + 1}. [${r.memory.type}] ${r.memory.content}\n   Relevance: ${Math.round(r.score * 100)}% | ${r.reason}`
          )
          .join('\n\n');

        return {
          content: [
            {
              type: 'text',
              text: `ðŸ§  Found ${results.length} relevant context items for "${task}":\n\n${contextText}`,
            },
          ],
        };
      }

      case 'cortex_guard': {
        if (!args) throw new Error('Missing arguments');
        const content = args['content'] as string;
        const defaultFilters = [
          'api_keys',
          'secrets',
          'emails',
          'urls_auth',
          'credit_cards',
          'phone_numbers',
          'ip_addresses',
          'pii',
        ] as const;
        type FilterType = (typeof defaultFilters)[number];
        const filters = (args['filters'] as FilterType[]) || [...defaultFilters];
        const mode = (args['mode'] as 'redact' | 'block' | 'warn') || 'redact';

        const result = guard.guard(content, { filters, mode });

        if (!result.wasFiltered) {
          return {
            content: [
              {
                type: 'text',
                text: 'âœ… No sensitive data detected. Content is safe to share.',
              },
            ],
          };
        }

        const detailsText = result.filterDetails
          ?.map((d) => `  - ${d.type}: ${d.count} found`)
          .join('\n');

        if (mode === 'block') {
          return {
            content: [
              {
                type: 'text',
                text: `â›” Sensitive data detected! Content blocked.\n\nDetected:\n${detailsText}`,
              },
            ],
          };
        }

        if (mode === 'warn') {
          return {
            content: [
              {
                type: 'text',
                text: `âš ï¸ Sensitive data detected but preserved:\n\nDetected:\n${detailsText}\n\nOriginal content:\n${result.content}`,
              },
            ],
          };
        }

        return {
          content: [
            {
              type: 'text',
              text: `ðŸ”’ Sensitive data redacted:\n\nFiltered:\n${detailsText}\n\nSafe content:\n${result.content}`,
            },
          ],
        };
      }

      case 'cortex_scan': {
        const scanPath = (args?.['path'] as string) || process.cwd();
        const shouldSave = args?.['save'] !== false;

        const scanner = new ProjectScanner();
        const result = await scanner.scan({ path: scanPath });

        // Save extracted memories if requested
        if (shouldSave && result.memories.length > 0) {
          let savedCount = 0;
          for (const memory of result.memories) {
            try {
              await store.add(memory);
              savedCount++;
            } catch {
              // Skip duplicates or errors
            }
          }
          result.summary.memoriesFound = savedCount;
        }

        // Format for LLM analysis
        const byTypeStr = Object.entries(result.summary.byType)
          .filter(([, count]) => count > 0)
          .map(([type, count]) => `${type}: ${count}`)
          .join(', ');

        const memorySummary = result.memories
          .slice(0, 20)
          .map(
            (m, i) =>
              `${i + 1}. [${m.type}] ${m.content.slice(0, 100)}${m.content.length > 100 ? '...' : ''}`
          )
          .join('\n');

        return {
          content: [
            {
              type: 'text',
              text:
                `ðŸ“Š Project Scan Complete\n\n` +
                `Path: ${scanPath}\n` +
                `Files scanned: ${result.summary.filesScanned}\n` +
                `Memories ${shouldSave ? 'saved' : 'found'}: ${result.summary.memoriesFound}\n` +
                `By type: ${byTypeStr}\n` +
                `Sources: ${result.summary.sources.slice(0, 5).join(', ')}${result.summary.sources.length > 5 ? '...' : ''}\n\n` +
                `Extracted context:\n${memorySummary}\n\n` +
                `ðŸ’¡ You can now use these memories for context. Ask me to analyze patterns or summarize the project architecture.`,
            },
          ],
        };
      }

      case 'cortex_auto_save': {
        if (!args) throw new Error('Missing arguments');
        const summary = args['conversation_summary'] as string;
        const memories = args['memories'] as Array<{
          content: string;
          type: string;
          tags?: string[];
        }>;

        if (!memories || memories.length === 0) {
          return {
            content: [
              {
                type: 'text',
                text: 'ðŸ“ No memories to save from this conversation.',
              },
            ],
          };
        }

        let savedCount = 0;
        const errors: string[] = [];

        for (const memory of memories) {
          try {
            await store.add({
              content: memory.content,
              type: memory.type as Memory['type'],
              source: 'auto-save',
              tags: memory.tags || ['auto-saved'],
            });
            savedCount++;
          } catch (_e) {
            errors.push(memory.content.slice(0, 50));
          }
        }

        return {
          content: [
            {
              type: 'text',
              text:
                `ðŸ§  Auto-Save Complete\n\n` +
                `Conversation: ${summary.slice(0, 100)}${summary.length > 100 ? '...' : ''}\n` +
                `Memories saved: ${savedCount}/${memories.length}\n` +
                (errors.length > 0 ? `\nâš ï¸ Skipped ${errors.length} duplicates` : '') +
                `\n\nâœ… Context will be available in future sessions.`,
            },
          ],
        };
      }

      case 'cortex_remember': {
        if (!args) throw new Error('Missing arguments');
        const content = args['content'] as string;
        const type = (args['type'] as Memory['type']) || 'note';
        const tags = args['tags'] as string[] | undefined;

        const id = await store.add({
          content,
          type,
          source: 'quick-remember',
          tags: tags || ['remembered'],
        });

        return {
          content: [
            {
              type: 'text',
              text: `âœ“ Remembered: "${content.slice(0, 100)}${content.length > 100 ? '...' : ''}" (ID: ${id})`,
            },
          ],
        };
      }

      case 'cortex_recall': {
        if (!args) throw new Error('Missing arguments');
        const query = args['query'] as string;
        const limit = (args['limit'] as number) || 5;

        // Use router for intelligent context retrieval
        const results = await router.routeWithScores({ task: query, limit });

        if (results.length === 0) {
          return {
            content: [
              {
                type: 'text',
                text: `ðŸ” No relevant memories found for "${query}". This might be a new topic.`,
              },
            ],
          };
        }

        const contextText = results
          .map(
            (r, i) =>
              `${i + 1}. [${r.memory.type}] ${r.memory.content}\n   Relevance: ${Math.round(r.score * 100)}%`
          )
          .join('\n\n');

        return {
          content: [
            {
              type: 'text',
              text:
                `ðŸ§  Recalled ${results.length} memories for "${query}":\n\n${contextText}\n\n` +
                `ðŸ’¡ Use this context to inform your responses.`,
            },
          ],
        };
      }

      default:
        throw new Error(`Unknown tool: ${name}`);
    }
  } catch (error) {
    return {
      content: [
        {
          type: 'text',
          text: `Error: ${error instanceof Error ? error.message : String(error)}`,
        },
      ],
      isError: true,
    };
  }
});

// Start server
async function main() {
  const args = process.argv.slice(2);

  // Handle setup command (delegates to CLI)
  if (args.includes('--setup')) {
    console.log('ðŸš€ Delegating to Cortex CLI for setup...');
    const { execSync } = await import('node:child_process');
    try {
      execSync('npx -y @ecuabyte/cortex-cli setup', { stdio: 'inherit' });
      process.exit(0);
    } catch (e) {
      console.error('âŒ Setup failed:', e);
      process.exit(1);
    }
  }

  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error('Cortex MCP server running on stdio');
}

main().catch((error) => {
  console.error('Server error:', error);
  process.exit(1);
});
